# datamigration:
千万级(线上1.23亿)sqlserver数据转储mongodb,根据ID范围确定线程数以及单个线程处理的页数;
耗时:7.5kw数据耗时19分半
### 操作接口:

- GET - localhost:8080/maxid  查看ID最大值
- GET - localhost:8080/migration 开始转储数据
- GET - localhost:8080/dropcollection 删除mongodb集合
- GET - localhost:8080/exceptiondata?begin=&end= 手动处理异常数据(参数传begin 和 end, 类型 long)  
- ~~(弃用)GET - localhost:8080/testdd 测试钉钉消息机器人~~

### 注意事项:
- 瓶颈主要来源于sql查询和mongodb的写入过程(坑:sqlserver不支持分页查询);
- 优化查询可以把[ SELECT * ] 改成查询相应字段,减少存储空间;  
- 其次是运行该程序的主机CPU和内存性能;
- 若CPU和内存的性能不是很好,可以选择在main/job.java中增加单个线程处理页数(减少线程数)和减少一页查询的记录数(防止爆内存);
- 线上环境(-prod),测试环境(-test),开发环境(-dev),在application.yml中设置编译环境;
- 如果你是连接的远程服务器,还需要考虑网络的上下行速度;
- 使用try-catch来对数据库操作做一个异常捕获,看是否有线程出现查询失败或者连接失效(或连接关闭)等情况;
- 新增异常处理,有的时候连接出现问题或一些超时操作导致的异常，需要单开线程来查询处理;
- 最好的方案是将程序放到mongodb同一台服务器上,写入数据太耗时了;
- 使用定时任务,在用户对数据库操作少的时候进行迁移,避免加班;
- 通过钉钉群机器人发送错误日志,实时关注运行情况;

### 警告
- 若在代码中出现公有(公司所有)或者个人的服务器地址配置,请勿恶意连接或者破坏数据,否则将追究其法律责任!
